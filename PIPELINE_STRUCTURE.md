# Pipeline Structure

Complete technical documentation of the voice conversation pipeline from call initiation to termination.

---

## ğŸ“ **COMPLETE PIPELINE FLOW**

```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                          PHASE 1: CALL INITIATION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Caller    â”‚ â”€â”€â”€â”€â”€â”€â†’ â”‚    Twilio    â”‚ â”€â”€â”€â”€â”€â”€â†’ â”‚  POST /twiml     â”‚
â”‚   Dials     â”‚         â”‚   Network    â”‚         â”‚  (main.py:53)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                           â”‚
                                                           â†“
                                                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                  â”‚  Generate TwiML  â”‚
                                                  â”‚  with WebSocket  â”‚
                                                  â”‚  URL + Phone #s  â”‚
                                                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                           â”‚
                                                           â†“
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                      PHASE 2: WEBSOCKET HANDSHAKE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  WebSocket Connection (websocket_handler.py:149)                            â”‚
â”‚  1. Accept WebSocket connection                                             â”‚
â”‚  2. Receive Twilio handshake (2 messages)                                   â”‚
â”‚  3. Extract: stream_sid, call_sid, To phone number                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â†“
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                      PHASE 3: AGENT CONFIGURATION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ConfigManager (config_manager.py)                                          â”‚
â”‚  1. Look up phone â†’ agent mapping (phone_configs + phone_mappings tables)   â”‚
â”‚  2. Load agent config from PostgreSQL (agent_config_versions table)         â”‚
â”‚  3. Parse: workflow, LLM, TTS, RAG configs                                  â”‚
â”‚  4. Validate: Ensure workflow exists (REQUIRED)                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â†“
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    PHASE 4: PIPELINE COMPONENT CREATION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Component Assembly (websocket_handler.py:203-445)                          â”‚
â”‚                                                                              â”‚
â”‚  A. Transport Layer (218-235)                                               â”‚
â”‚     â”œâ”€ TwilioFrameSerializer (auto-hangup if credentials present)          â”‚
â”‚     â””â”€ FastAPIWebsocketTransport (8kHz audio, bidirectional)               â”‚
â”‚                                                                              â”‚
â”‚  B. STT Filtering (652-677)                                                 â”‚
â”‚     â””â”€ STTMuteFilter (intelligent speech muting)                           â”‚
â”‚        â”œâ”€ MUTE_UNTIL_FIRST_BOT_COMPLETE: Blocks STT during greeting        â”‚
â”‚        â””â”€ CUSTOM: Per-node interruption control via callback               â”‚
â”‚                                                                              â”‚
â”‚  C. Speech-to-Text (523-532)                                                â”‚
â”‚     â””â”€ DeepgramFluxSTTService (v2, configurable EOT thresholds)            â”‚
â”‚                                                                              â”‚
â”‚  D. Frame Processors (254-263)                                              â”‚
â”‚     â”œâ”€ TranscriptionHandler (before LLM - captures user speech)            â”‚
â”‚     â””â”€ LLMOutputObserver (after LLM - tracks response latency)             â”‚
â”‚                                                                              â”‚
â”‚  E. LLM Service (265-308)                                                   â”‚
â”‚     â”œâ”€ Azure/OpenAI LLM (gpt-5-mini or custom)                             â”‚
â”‚     â””â”€ OpenAILLMContext (conversation context manager)                     â”‚
â”‚                                                                              â”‚
â”‚  F. Text-to-Speech (310-357)                                                â”‚
â”‚     â””â”€ ExtendedElevenLabsTTSService (SSML + pronunciation dicts)           â”‚
â”‚                                                                              â”‚
â”‚  G. RAG System (359-386) [OPTIONAL]                                         â”‚
â”‚     â”œâ”€ RAGKnowledgeBase (FAISS + SQLite + Bedrock)                         â”‚
â”‚     â””â”€ RAGProcessor (query detection + context injection)                  â”‚
â”‚                                                                              â”‚
â”‚  H. Workflow Orchestration (388-423) [REQUIRED]                             â”‚
â”‚     â”œâ”€ TransitionEvaluator (pattern + intent conditions)                   â”‚
â”‚     â”œâ”€ ActionExecutor (webhooks, logging, hangup)                          â”‚
â”‚     â””â”€ NodeManager (workflow state machine)                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Pipeline Construction (679-693)                                            â”‚
â”‚                                                                              â”‚
â”‚  [Input] â†’ [STTMuteFilter] â†’ [Deepgram STT] â†’ [TranscriptionHandler] â†’     â”‚
â”‚  [InterruptionHandler] â†’ [NodeManager] â†’ [RAGProcessor*] â†’ [Context] â†’     â”‚
â”‚  [LLM] â†’ [LLMOutputObserver] â†’ [TTS] â†’ [Output] â†’ [Context Assistant]      â”‚
â”‚                                                                              â”‚
â”‚  * RAG is optional and per-node configurable                               â”‚
â”‚  * STTMuteFilter blocks audio during bot greeting and per-node config      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â†“
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                      PHASE 5: RUNTIME PROCESSING LOOP
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  NodeManager Initialization (node_manager.py:124)                           â”‚
â”‚  â”œâ”€ Sets initial workflow node                                              â”‚
â”‚  â”œâ”€ Builds system prompt (global + node-specific)                           â”‚
â”‚  â”œâ”€ Pushes LLMMessagesUpdateFrame                                           â”‚
â”‚  â”œâ”€ Configures RAG for initial node                                         â”‚
â”‚  â””â”€ Executes on_entry actions                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                        â•”â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•—
                        â•‘   CONVERSATION LOOP   â•‘
                        â•šâ•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•
                                    â”‚
                                    â†“

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         USER SPEECH â†’ TRANSCRIPT                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                               â”‚
â”‚  1. AUDIO INPUT (Twilio â†’ Transport)                                         â”‚
â”‚     â””â”€ Mulaw 8kHz audio stream from Twilio                                   â”‚
â”‚                                                                               â”‚
â”‚  2. SPEECH-TO-TEXT (Deepgram Flux v2)                      [â±ï¸ ~0-1ms]      â”‚
â”‚     â”œâ”€ UserStartedSpeakingFrame â†’ TranscriptionHandler                      â”‚
â”‚     â”œâ”€ InterimTranscriptionFrame (partial results)                           â”‚
â”‚     â”œâ”€ UserStoppedSpeakingFrame â†’ Mark timestamp                            â”‚
â”‚     â””â”€ TranscriptionFrame â†’ Final transcript                                 â”‚
â”‚        â””â”€ LatencyTracker.mark_user_stopped()                                 â”‚
â”‚        â””â”€ LatencyTracker.mark_transcript_received()                          â”‚
â”‚                                                                               â”‚
â”‚  3. TRANSCRIPTION HANDLER (transcription_handler.py:72)                      â”‚
â”‚     â”œâ”€ Log user input: "ğŸ‘¤ User: {text}"                                    â”‚
â”‚     â””â”€ Push TranscriptionFrame downstream                                    â”‚
â”‚                                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         WORKFLOW ORCHESTRATION                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                               â”‚
â”‚  4. NODE MANAGER (node_manager.py:175)                     [â±ï¸ ~500ms GAP]  â”‚
â”‚     â”œâ”€ Receive TranscriptionFrame                                            â”‚
â”‚     â”œâ”€ Update conversation history                                           â”‚
â”‚     â”œâ”€ Increment turn count                                                  â”‚
â”‚     â”œâ”€ Collect data (if configured)                                          â”‚
â”‚     â”‚  â””â”€ Extract: full_input, topic_name, llm_extract                       â”‚
â”‚     â”‚                                                                          â”‚
â”‚     â”œâ”€ TRANSITION EVALUATION (transition_evaluator.py:43)                    â”‚
â”‚     â”‚  â”œâ”€ Pattern-based (fast):                                              â”‚
â”‚     â”‚  â”‚  â”œâ”€ timeout:Xs                                                       â”‚
â”‚     â”‚  â”‚  â”œâ”€ max_turns:N                                                      â”‚
â”‚     â”‚  â”‚  â”œâ”€ contains:keyword                                                 â”‚
â”‚     â”‚  â”‚  â””â”€ user_responded                                                   â”‚
â”‚     â”‚  â”‚                                                                       â”‚
â”‚     â”‚  â””â”€ Intent-based (LLM ~100-150ms):                                     â”‚
â”‚     â”‚     â”œâ”€ intent:{intent_id}                                               â”‚
â”‚     â”‚     â”œâ”€ intent:no_match (fallback)                                       â”‚
â”‚     â”‚     â””â”€ Single batch LLM call for all intents                           â”‚
â”‚     â”‚        â””â”€ Uses gpt-4o-mini with descriptions + examples                â”‚
â”‚     â”‚                                                                          â”‚
â”‚     â””â”€ IF TRANSITION TRIGGERED:                                              â”‚
â”‚        â”œâ”€ Execute on_exit actions (current node)                             â”‚
â”‚        â”œâ”€ Update state & history                                             â”‚
â”‚        â”œâ”€ Switch to new node                                                 â”‚
â”‚        â”œâ”€ Build new system prompt (global + new node)                        â”‚
â”‚        â”œâ”€ Apply history windowing                                            â”‚
â”‚        â”œâ”€ Push LLMMessagesUpdateFrame (context switch)                       â”‚
â”‚        â”œâ”€ Configure RAG for new node (enable/disable)                        â”‚
â”‚        â”œâ”€ Execute on_entry actions (new node)                                â”‚
â”‚        â””â”€ Check for end_call or proactive auto-transitions                   â”‚
â”‚                                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    KNOWLEDGE RETRIEVAL (OPTIONAL)                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                               â”‚
â”‚  5. RAG PROCESSOR (rag_processor.py:64)                     [â±ï¸ ~50-200ms]  â”‚
â”‚     â”œâ”€ Check if RAG enabled for current node                                 â”‚
â”‚     â”œâ”€ Smart query detection (skip greetings/casual chat)                    â”‚
â”‚     â”‚  â””â”€ Checks: what/how/why/when/where/tell/explain/can you               â”‚
â”‚     â”‚                                                                          â”‚
â”‚     â”œâ”€ IF KNOWLEDGE-SEEKING QUERY:                                           â”‚
â”‚     â”‚  â”œâ”€ LatencyTracker.mark_rag_started()                                  â”‚
â”‚     â”‚  â”œâ”€ RAGService.search() (rag_service.py)                               â”‚
â”‚     â”‚  â”‚  â”œâ”€ Generate query embedding (AWS Bedrock Titan)                    â”‚
â”‚     â”‚  â”‚  â”œâ”€ Vector search (FAISS HNSW index)                                â”‚
â”‚     â”‚  â”‚  â”œâ”€ Full-text search (SQLite FTS5)                                  â”‚
â”‚     â”‚  â”‚  â””â”€ Hybrid fusion (RRF algorithm)                                   â”‚
â”‚     â”‚  â”‚                                                                       â”‚
â”‚     â”‚  â”œâ”€ LatencyTracker.mark_rag_completed(chunk_count)                     â”‚
â”‚     â”‚  â”œâ”€ Format context from chunks                                         â”‚
â”‚     â”‚  â”œâ”€ Push LLMMessagesUpdateFrame (ephemeral system message)             â”‚
â”‚     â”‚  â””â”€ Log: "ğŸ§  RAG: {N} chunks | {M} sources"                            â”‚
â”‚     â”‚                                                                          â”‚
â”‚     â””â”€ Push TranscriptionFrame downstream                                     â”‚
â”‚                                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           LLM GENERATION                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                               â”‚
â”‚  6. CONTEXT AGGREGATOR (Pipecat built-in)                                    â”‚
â”‚     â”œâ”€ Aggregate context messages:                                           â”‚
â”‚     â”‚  â”œâ”€ System prompt (global + node-specific)                             â”‚
â”‚     â”‚  â”œâ”€ Conversation history (windowed if configured)                      â”‚
â”‚     â”‚  â”œâ”€ RAG context (if retrieved)                                         â”‚
â”‚     â”‚  â””â”€ Current user input                                                 â”‚
â”‚     â”‚                                                                          â”‚
â”‚     â””â”€ Push to LLM service                                                   â”‚
â”‚                                                                               â”‚
â”‚  7. LLM SERVICE (OpenAI/Azure)                               [â±ï¸ ~400-800ms] â”‚
â”‚     â”œâ”€ LLMFullResponseStartFrame â†’ LLMOutputObserver                         â”‚
â”‚     â”‚  â””â”€ LatencyTracker.mark_llm_started()                                  â”‚
â”‚     â”‚                                                                          â”‚
â”‚     â”œâ”€ Stream response chunks (LLMTextFrame)                                 â”‚
â”‚     â”‚  â””â”€ LLMOutputObserver collects chunks                                  â”‚
â”‚     â”‚                                                                          â”‚
â”‚     â””â”€ LLMFullResponseEndFrame                                               â”‚
â”‚        â”œâ”€ LatencyTracker.mark_llm_completed(response)                        â”‚
â”‚        â”œâ”€ Log: "ğŸ¤– Assistant: {response}"                                    â”‚
â”‚        â””â”€ Update conversation history (context_aggregator.assistant())       â”‚
â”‚                                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         TEXT-TO-SPEECH SYNTHESIS                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                               â”‚
â”‚  8. TTS SERVICE (ElevenLabs)                                 [â±ï¸ ~200-400ms] â”‚
â”‚     â”œâ”€ Receive TextFrame/LLMTextFrame                                        â”‚
â”‚     â”œâ”€ Parse SSML tags (if enabled):                                         â”‚
â”‚     â”‚  â”œâ”€ <break time="500ms"/>                                              â”‚
â”‚     â”‚  â”œâ”€ <prosody rate="slow">                                              â”‚
â”‚     â”‚  â””â”€ <emphasis level="strong">                                          â”‚
â”‚     â”‚                                                                          â”‚
â”‚     â”œâ”€ Apply pronunciation dictionaries (if configured):                     â”‚
â”‚     â”‚  â””â”€ Send dictionary locators in WebSocket initial context              â”‚
â”‚     â”‚     â””â”€ elevenlabs_extended.py:65-101                                   â”‚
â”‚     â”‚                                                                          â”‚
â”‚     â”œâ”€ WebSocket to ElevenLabs API                                           â”‚
â”‚     â”‚  â””â”€ Stream audio chunks                                                â”‚
â”‚     â”‚                                                                          â”‚
â”‚     â””â”€ BotStartedSpeakingFrame â†’ LLMOutputObserver                           â”‚
â”‚        â”œâ”€ LatencyTracker.mark_tts_started()                                  â”‚
â”‚        â””â”€ Log turn summary with full latency breakdown                       â”‚
â”‚                                                                               â”‚
â”‚  9. AUDIO OUTPUT (Transport)                                                 â”‚
â”‚     â””â”€ Stream mulaw 8kHz audio to Twilio                                     â”‚
â”‚                                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                        â•”â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•—
                        â•‘  LOOP BACK TO STEP 1  â•‘
                        â•‘   (Next user turn)     â•‘
                        â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                         PHASE 6: CALL TERMINATION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Termination Triggers                                                         â”‚
â”‚                                                                               â”‚
â”‚  A. CLIENT DISCONNECT (websocket_handler.py:458)                             â”‚
â”‚     â”œâ”€ User hangs up â†’ on_client_disconnected event                          â”‚
â”‚     â”œâ”€ task.cancel() â†’ Stop pipeline immediately                             â”‚
â”‚     â””â”€ TwilioFrameSerializer auto-hangs up call (if credentials present)     â”‚
â”‚                                                                               â”‚
â”‚  B. END_CALL NODE (node_manager.py:284)                                      â”‚
â”‚     â”œâ”€ Workflow reaches node with type="end"                                 â”‚
â”‚     â”œâ”€ Deliver closing message (if any)                                      â”‚
â”‚     â”œâ”€ Execute hangup action immediately                                     â”‚
â”‚     â”‚  â””â”€ action_executor.py:138                                             â”‚
â”‚     â”‚     â””â”€ Calls TwilioFrameSerializer._hang_up_call()                     â”‚
â”‚     â”‚        â””â”€ Twilio REST API: POST /Calls/{CallSid}.json (Status=completed)â”‚
â”‚     â””â”€ 3-second pause, then disconnect                                       â”‚
â”‚                                                                               â”‚
â”‚  C. MANUAL HANGUP ACTION (action_executor.py:138)                            â”‚
â”‚     â””â”€ Node on_entry/on_exit action triggers hangup                          â”‚
â”‚                                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Session Summary Logging (websocket_handler.py:476)                          â”‚
â”‚                                                                               â”‚
â”‚  1. LATENCY SUMMARY (latency_tracker.py:331)                                 â”‚
â”‚     â”œâ”€ STT Delay: avg/min/max                                                â”‚
â”‚     â”œâ”€ Transcriptâ†’LLM Gap: avg/min/max (pipeline overhead)                   â”‚
â”‚     â”œâ”€ RAG Processing: avg/min/max (if used)                                 â”‚
â”‚     â”œâ”€ LLM Processing: avg/min/max                                           â”‚
â”‚     â”œâ”€ LLMâ†’TTS Gap: avg/min/max (pipeline + TTS latency)                     â”‚
â”‚     â””â”€ Pipeline Total: avg/min/max                                           â”‚
â”‚                                                                               â”‚
â”‚  2. WORKFLOW SUMMARY (node_manager.py:509)                                   â”‚
â”‚     â”œâ”€ Final node                                                            â”‚
â”‚     â”œâ”€ Total transitions                                                     â”‚
â”‚     â”œâ”€ Transition history                                                    â”‚
â”‚     â”œâ”€ Collected data                                                        â”‚
â”‚     â””â”€ Conversation turn count                                               â”‚
â”‚                                                                               â”‚
â”‚  3. SESSION CLEANUP                                                          â”‚
â”‚     â”œâ”€ Close WebSocket connection                                            â”‚
â”‚     â”œâ”€ Log session duration                                                  â”‚
â”‚     â””â”€ Release resources                                                     â”‚
â”‚                                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                            ğŸ¬ SESSION COMPLETE
```

---

## ğŸ” **DETAILED STAGE EXPLANATIONS**

### **PHASE 1: Call Initiation**
- **app/main.py:53** - `/twiml` webhook receives Twilio's POST request with phone numbers
- Generates TwiML XML response with WebSocket URL and phone number parameters
- Twilio establishes bidirectional media stream over WebSocket

### **PHASE 2: WebSocket Handshake**
- **websocket_handler.py:149** - Accepts connection, extracts stream_sid, call_sid, phone numbers
- Creates unique session_id for tracking
- Prepares for agent configuration lookup

### **PHASE 3: Agent Configuration**
- **config_manager.py** - Database-backed configuration loader
  - Maps phone number â†’ agent via `phone_configs` + `phone_mappings` tables
  - Loads agent config from `agent_config_versions` table
  - Validates workflow exists (REQUIRED - no traditional mode)
  - Redis caching with manual invalidation for hot reload

### **PHASE 4: Pipeline Component Creation**
Assembles the Pipecat pipeline with 11 distinct components:

1. **Transport** - Bidirectional WebSocket with Twilio serialization
2. **STTMuteFilter** - Intelligent STT muting (NEW in v0.0.94)
   - `MUTE_UNTIL_FIRST_BOT_COMPLETE`: Blocks STT during initial greeting
   - `CUSTOM`: Per-node interruption control via callback
3. **STT** - Deepgram Flux v2 (sub-millisecond latency)
4. **TranscriptionHandler** - User speech event tracking (before LLM)
5. **InterruptionHandler** - MinWordsInterruptionStrategy filtering
6. **NodeManager** - Workflow state machine orchestrator
7. **RAGProcessor** - Knowledge retrieval (optional, per-node)
8. **ContextAggregator** - Message assembly for LLM
9. **LLM** - OpenAI/Azure GPT-5-mini or custom
10. **LLMOutputObserver** - Response tracking (after LLM)
11. **TTS** - ElevenLabs with SSML + pronunciation dictionaries

### **PHASE 5: Runtime Processing Loop**
**The core conversation pipeline with 9 distinct stages:**

#### **Stage 1-3: User Input â†’ Transcript** (~0-1ms)
- Deepgram Flux v2 processes audio in real-time
- Emits: `UserStartedSpeakingFrame` â†’ `InterimTranscriptionFrame` â†’ `UserStoppedSpeakingFrame` â†’ `TranscriptionFrame`
- **latency_tracker.py** captures precise timestamps

#### **Stage 4: Workflow Orchestration** (~500ms - **Main Bottleneck**)
**node_manager.py** - The brain of the system:
- Updates conversation history
- Collects structured data (`full_input`, `topic_name`, `llm_extract`)
- **Evaluates transitions** via hybrid approach:
  - **Pattern-based** (<1ms): timeout, max_turns, contains, user_responded
  - **Intent** (~100-150ms): Uses gpt-4o-mini for batch intent classification
- **If transition triggered**:
  - Executes `on_exit` actions (webhooks, logging)
  - Switches node context (new system prompt)
  - Applies history windowing
  - Configures per-node RAG (enable/disable dynamically)
  - Executes `on_entry` actions
  - Checks for special nodes (`end_call`, proactive auto-transitions)

#### **Stage 5: Knowledge Retrieval** (~50-200ms, optional)
**rag_processor.py** + **rag_service.py**:
- Smart query detection (skips greetings/casual chat)
- **Hybrid search** (fastest to slowest):
  1. FAISS HNSW vector search
  2. SQLite FTS5 full-text search
  3. RRF (Reciprocal Rank Fusion) for result merging
- Injects ephemeral system message with retrieved context

#### **Stage 6-7: LLM Generation** (~400-800ms)
- **ContextAggregator** builds final message array:
  - System prompt (global + node-specific)
  - Windowed conversation history
  - RAG context (if retrieved)
  - Current user input
- **OpenAI/Azure LLM** streams response chunks
- **LLMOutputObserver** tracks timing and logs response

#### **Stage 8-9: TTS Synthesis & Audio Output** (~200-400ms)
**elevenlabs_extended.py**:
- Parses SSML tags for pauses, prosody, emphasis
- Applies pronunciation dictionaries via WebSocket initial context
- Streams audio chunks to Twilio in mulaw 8kHz format
- **Latency tracking** measures LLMâ†’TTS gap (pipeline overhead + TTS API)

### **PHASE 6: Call Termination**
Three termination paths:
1. **Client disconnect** â†’ `task.cancel()` â†’ Auto-hangup via Twilio REST API
2. **end_call node** â†’ Immediate hangup action â†’ Twilio API call
3. **Manual hangup action** â†’ Triggered by workflow on_entry/on_exit

**Session summaries** log:
- Per-turn latency breakdown (STT, gaps, RAG, LLM, TTS)
- Aggregated statistics (avg/min/max)
- Workflow state (transitions, collected data)

---

## âš¡ **LATENCY BREAKDOWN** (Typical Values)

```
STT Delay:             0-1ms    (Deepgram Flux v2 is near-instant)
Transcriptâ†’LLM Gap:    ~500ms   ğŸ”´ MAIN BOTTLENECK
  â”œâ”€ Pipeline overhead: ~100ms
  â”œâ”€ NodeManager processing: ~400ms
  â”‚  â”œâ”€ Transition evaluation: ~10-200ms (intent conditions)
  â”‚  â”œâ”€ Context assembly: ~50ms
  â”‚  â””â”€ Frame propagation: ~40ms
RAG Processing:        ~50-200ms (if enabled)
LLM Processing:        ~400-800ms
LLMâ†’TTS Gap:           ~200-400ms
  â”œâ”€ Pipeline overhead: ~100ms
  â””â”€ TTS API latency: ~100-300ms
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Pipeline Total:        ~1200-1900ms (1.2-1.9s end-to-end)
```

**Key Insight**: The **Transcriptâ†’LLM Gap** (~500ms) is the dominant latency source, primarily from:
- Pipecat frame processing overhead
- NodeManager transition evaluation (especially intent conditions using LLM)
- Context assembly and prompt building

---

## ğŸ¯ **PURPOSE OF EACH COMPONENT**

| Component | Purpose | Key Files |
|-----------|---------|-----------|
| **Transport** | Bidirectional WebSocket audio streaming (Twilio â†” Pipeline) | `websocket_handler.py:218` |
| **STTMuteFilter** | Intelligent STT muting during bot speech & per-node interruption control | `websocket_handler.py:652` |
| **Deepgram STT** | Real-time speech recognition with configurable EOT thresholds | `websocket_handler.py:523` |
| **TranscriptionHandler** | Captures user speech events & timestamps (before LLM) | `websocket_handler.py:61` |
| **InterruptionHandler** | MinWordsInterruptionStrategy filtering for false positives | `websocket_handler.py:635` |
| **NodeManager** | Workflow orchestration: transitions, context switching, data collection | `node_manager.py:55` |
| **TransitionEvaluator** | Hybrid pattern + LLM-based condition evaluation | `transition_evaluator.py:17` |
| **ActionExecutor** | Executes actions: log, webhook, hangup, custom | `action_executor.py:18` |
| **RAGProcessor** | Smart query detection + knowledge retrieval | `rag_processor.py:18` |
| **RAGKnowledgeBase** | Hybrid search (FAISS + SQLite FTS5 + RRF fusion) | `rag_service.py` |
| **ContextAggregator** | Assembles messages for LLM (system + history + RAG + user) | Pipecat built-in |
| **LLM Service** | GPT-5-mini (Azure/OpenAI) for conversation generation | `websocket_handler.py:265` |
| **LLMOutputObserver** | Tracks LLM response timing & logs output (after LLM) | `websocket_handler.py:95` |
| **ExtendedElevenLabsTTS** | SSML parsing + pronunciation dictionaries | `elevenlabs_extended.py:9` |
| **LatencyTracker** | High-precision turn-by-turn and session latency metrics | `latency_tracker.py:8` |
| **AnalyticsObserver** | Captures Pipecat MetricsFrames & writes to PostgreSQL | `analytics_observer.py:44` |
| **TurnTrackingObserver** | Native Pipecat turn tracking with duration & interruption status | Pipecat built-in |

---

## ğŸ“Š **FRAME FLOW DIAGRAM**

```
User speaks â†’ Audio packets â†’ Twilio â†’ WebSocket
                                           â”‚
                                           â†“
                                    Transport.input()
                                           â”‚
                                           â†“ AudioRawFrame
                                    STTMuteFilter
                         (blocks audio during bot speech or
                          when node.interruptions_enabled=false)
                                           â”‚
                                           â†“ AudioRawFrame (if not muted)
                                    Deepgram STT
                                           â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â†“                      â†“                      â†“
          UserStartedSpeakingFrame  InterimTranscriptionFrame  UserStoppedSpeakingFrame
                    â”‚                                              â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                           â†“
                                    TranscriptionFrame
                                           â”‚
                                           â†“
                                  TranscriptionHandler
                              (logs, marks timestamps)
                                           â”‚
                                           â†“
                                  InterruptionHandler
                         (MinWordsInterruptionStrategy filtering)
                                           â”‚
                                           â†“
                                     NodeManager
                         (evaluate transitions, switch context)
                                           â”‚
                                           â†“
                                    RAGProcessor [optional]
                              (inject knowledge context)
                                           â”‚
                                           â†“
                                  ContextAggregator.user()
                              (build message array)
                                           â”‚
                                           â†“
                                      LLM Service
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â†“                      â†“                      â†“
          LLMFullResponseStartFrame    LLMTextFrame    LLMFullResponseEndFrame
                    â”‚                      â”‚                      â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                           â†“
                                    LLMOutputObserver
                              (collect response, log)
                                           â”‚
                                           â†“ TextFrame
                                      TTS Service
                                           â”‚
                                           â†“ TTSAudioRawFrame
                                   Transport.output()
                                           â”‚
                                           â†“
                                       WebSocket
                                           â”‚
                                           â†“
                                  Twilio â†’ User hears
```

---

## ğŸ”„ **STATE TRANSITIONS**

### **NodeManager State Machine**
```
Initial State:
  current_node_id: workflow.initial_node
  turn_count: 0
  transition_count: 0
  conversation_history: []
  collected_data: {}

On User Input:
  1. Add to conversation_history
  2. Increment turn_count
  3. Collect data (if configured)
  4. Evaluate transitions (first match wins)
  5. If matched:
     a. Execute on_exit actions
     b. Increment transition_count
     c. Reset turn_count
     d. Update current_node_id
     e. Switch LLM context (new prompt + windowed history)
     f. Configure RAG for new node
     g. Execute on_entry actions
     h. Check for special nodes (end_call, proactive auto-transitions)

Special Nodes:
  - type: "end" â†’ Immediate hangup after delivering closing message
  - proactive: true + always â†’ Auto-transition after ~4s (LLM + TTS + audio)

Safety Limits:
  - Max transitions: workflow.max_transitions (default: 50)
  - History window: workflow.history_window messages (0 = unlimited)
```

---

## ğŸš€ **OPTIMIZATION OPPORTUNITIES**

Based on latency analysis, potential optimizations:

1. **Transcriptâ†’LLM Gap (~500ms bottleneck)**
   - Cache compiled system prompts
   - Optimize frame processing (reduce await chains)
   - Parallelize transition evaluation with frame forwarding
   - Use faster Azure region or OpenAI standard endpoint

2. **NodeManager Transition Evaluation**
   - Pattern-based conditions first (fast path)
   - Intent classification cached per user input per node
   - Consider reducing intent count per node

3. **RAG Processing**
   - Pre-warm FAISS index on startup
   - Cache embeddings for common queries
   - Use vector caching layer

4. **TTS Generation**
   - Use ElevenLabs streaming mode (not WebSocket batching)
   - Pre-generate common phrases (greetings, closings)
   - Optimize SSML parsing

5. **Pipeline Overhead**
   - Reduce frame copies (use zero-copy where possible)
   - Optimize async task scheduling
   - Profile frame processor chain for bottlenecks

---

## ğŸ“ **KEY DESIGN DECISIONS**

1. **Workflow-Only Mode**: Removed traditional agent configuration for simplicity
2. **Per-Node RAG**: RAG can be enabled/disabled dynamically per conversation stage
3. **Hybrid Transition Evaluation**: Pattern-based (fast) + LLM-based (flexible)
4. **Precise Latency Tracking**: Frame arrival timestamps capture true pipeline overhead
5. **Hot Reload**: Agent configs cached with mtime-based invalidation
6. **Multi-Tenant**: Phone mapping enables isolated tenant/agent configurations
7. **Auto-Hangup**: Twilio REST API integration for graceful call termination
8. **Session Isolation**: Unique session_id per call for debugging and analytics
9. **STTMuteFilter Integration** (v0.0.94): Intelligent STT muting reduces false transcripts
   - Mutes during initial bot greeting (prevents echo/noise)
   - Per-node interruption control via custom callback
   - Reduces Deepgram API costs by blocking audio when appropriate
10. **Native Pipecat Observers**: Using built-in MetricsLogObserver, UserBotLatencyLogObserver, TurnTrackingObserver for automatic metrics collection

This architecture enables **multi-tenant**, **workflow-driven**, **context-aware** voice conversations with **sub-2-second** end-to-end latency and **comprehensive observability**.
